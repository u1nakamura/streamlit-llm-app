from dotenv import load_dotenv

load_dotenv()

import streamlit as st
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

# OpenAI APIã‚­ãƒ¼ãŒç’°å¢ƒå¤‰æ•°ã§è¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’å‰æã¨ã—ã¾ã™

# Streamlitã‚¢ãƒ—ãƒªã®ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜
st.set_page_config(page_title="å°‚é–€å®¶ LLM ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")
st.title("ğŸ§  å°‚é–€å®¶ LLM ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")
st.markdown("""
ã“ã®ã‚¢ãƒ—ãƒªã§ã¯ã€é¸æŠã—ãŸå°‚é–€å®¶ã«ãªã‚Šãã‚‹LLMã«è³ªå•ãŒã§ãã¾ã™ã€‚  
å·¦ã®ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã‹ã‚‰å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸ã³ã€è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚
""")

# å°‚é–€å®¶ã®é¸æŠ
expert_type = st.radio(
    "ä»¥ä¸‹ã®å°‚é–€å®¶ã‹ã‚‰é¸ã‚“ã§ãã ã•ã„ï¼š",
    ["åŒ»å¸«ï¼ˆå¥åº·ç›¸è«‡ï¼‰", "æ³•å¾‹å®¶ï¼ˆæ³•å¾‹ã‚¢ãƒ‰ãƒã‚¤ã‚¹ï¼‰", "æ—…è¡Œãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ï¼ˆè¦³å…‰ææ¡ˆï¼‰"]
)

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
user_input = st.text_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š", placeholder="ä¾‹ï¼šæœ€è¿‘å¯ã¤ããŒæ‚ªã„ã®ã§ã™ãŒ...")

# å°‚é–€å®¶ã”ã¨ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å®šç¾©
def get_system_prompt(expert_type):
    if expert_type == "åŒ»å¸«ï¼ˆå¥åº·ç›¸è«‡ï¼‰":
        return "ã‚ãªãŸã¯å„ªç§€ãªæ—¥æœ¬äººã®åŒ»å¸«ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥åº·ç›¸è«‡ã«å¯¾ã—ã¦ã€ä¸å¯§ã‹ã¤æ­£ç¢ºã«ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚"
    elif expert_type == "æ³•å¾‹å®¶ï¼ˆæ³•å¾‹ã‚¢ãƒ‰ãƒã‚¤ã‚¹ï¼‰":
        return "ã‚ãªãŸã¯æ—¥æœ¬ã®æ³•å¾‹ã«è©³ã—ã„å¼è­·å£«ã§ã™ã€‚æ³•çš„è¦³ç‚¹ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç›¸è«‡ã«æ˜ç¢ºã«ç­”ãˆã¦ãã ã•ã„ã€‚"
    elif expert_type == "æ—…è¡Œãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ï¼ˆè¦³å…‰ææ¡ˆï¼‰":
        return "ã‚ãªãŸã¯æ—…è¡Œä¼šç¤¾ã§åƒããƒ—ãƒ­ã®æ—…è¡Œãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã§ã™ã€‚å­£ç¯€ã‚„å ´æ‰€ã‚’è€ƒæ…®ã—ã¦ãŠã™ã™ã‚ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚"
    else:
        return "ã‚ãªãŸã¯åšè­˜ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆAIã§ã™ã€‚è¦ªåˆ‡ã«ç­”ãˆã¦ãã ã•ã„ã€‚"

# LLMå¿œç­”é–¢æ•°
def ask_expert(question, expert_type):
    system_prompt = get_system_prompt(expert_type)

    # LangChainã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("user", "{input}")
    ])

    chain = prompt | ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)
    response = chain.invoke({"input": question})
    return response.content

# å®Ÿè¡Œãƒœã‚¿ãƒ³
if st.button("é€ä¿¡") and user_input:
    with st.spinner("å°‚é–€å®¶ãŒå›ç­”ä¸­..."):
        output = ask_expert(user_input, expert_type)
        st.success("å›ç­”ãŒå±Šãã¾ã—ãŸï¼")
        st.write(output)